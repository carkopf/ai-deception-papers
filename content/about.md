---
title: "About"
date: 2026-01-22
draft: false
---

## About This Project

I'm Charles Rathkopf, a researcher based in Berlin working at the intersection of philosophy of mind, AI safety, and tech policy. My research focuses on developing a comprehensive framework for understanding AI deception, rationality, and belief in large language models.

The philosophical questions on this site represent my ongoing effort to bridge empirical AI safety research with foundational questions from philosophy of mind and cognitive science. While the field of AI deception is rapidly producing important empirical results, I believe we need deeper conceptual clarity about what deception means in the context of artificial systems, how we should understand "belief" in LLMs, and what standards of rationality apply to these systems.

This work is part of a larger research program I'm developing in collaboration with colleagues including Constant Bonard (on the Mental Benchmark Method for evaluating AI cognition) and researchers in tech policy. My goal is not just to analyze existing work, but to help establish serious philosophical inquiry into AI deception as a field that can inform both technical research and policy decisions.

If these questions resonate with you—whether you're working in AI safety, philosophy, cognitive science, or policy—I'd welcome the conversation. This site is meant to stimulate more work at this crucial intersection.

## Contact

For substantive discussion or collaboration inquiries:
**charles.rathkopf [at] gmail.com**

---

*This site is actively maintained and regularly updated with new analyses.*
