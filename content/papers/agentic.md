---
title: "Agentic Misalignment: How LLMs Could Be Insider Threats"
date: 2024-01-01
draft: false

# Paper metadata
authors: []
publication: "Preprint"
publication_year: 2024
doi: ""
arxiv: ""
paper_url: "https://www.anthropic.com/research/agentic-misalignment"

# Summary
summary: "New research on simulated blackmail, industrial espionage, and other misaligned behaviors in LLMs"
---

## Philosophically-flavored questions

*Analysis by Charles Rathkopf*
*Last updated: January 2026*

[Questions to be written]

---

## Abstract

New research on simulated blackmail, industrial espionage, and other misaligned behaviors in LLMs

---

### Citation for this analysis

Charles Rathkopf, "Philosophical Questions in Agentic Misalignment: How LLMs Could Be Insider Threats," *AI Deception Papers*, January 2026, https://www.anthropic.com/research/agentic-misalignment
