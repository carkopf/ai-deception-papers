---
title: "Secret Collusion among AI Agents: Multi-Agent Deception via Steganography"
date: 2025-01-01
draft: false

# Paper metadata
authors: ["Motwani, Sumeet Ramesh", "Baranchuk, Mikhail", "Strohmeier, Martin", "Bolina, Vijay", "Torr, Philip H. S.", "Hammond, Lewis", "de Witt, Christian Schroeder"]
publication: "arXiv"
publication_year: 2025
doi: "10.48550/arXiv.2402.07510"
arxiv: "2402.07510"
paper_url: "https://doi.org/10.48550/arXiv.2402.07510"

# Summary
summary: "Recent capability increases in large language models (LLMs) open up applications in which groups of communicating generative AI agents solve joint tasks. This poses privacy and security challenges concerning the unauthorised sharing of information, or other unwanted forms of agent coordination."
---

## Philosophically-flavored questions

*Analysis by Charles Rathkopf*
*Last updated: January 2026*

[Questions to be written]

---

## Abstract

Recent capability increases in large language models (LLMs) open up applications in which groups of communicating generative AI agents solve joint tasks. This poses privacy and security challenges concerning the unauthorised sharing of information, or other unwanted forms of agent coordination. Modern steganographic techniques could render such dynamics hard to detect. In this paper, we comprehensively formalise the problem of secret collusion in systems of generative AI agents by drawing on relevant concepts from both AI and security literature. We study incentives for the use of steganography, and propose a variety of mitigation measures. Our investigations result in a model evaluation framework that systematically tests capabilities required for various forms of secret collusion. We provide extensive empirical results across a range of contemporary LLMs. While the steganographic capabilities of current models remain limited, GPT-4 displays a capability jump suggesting the need for continuous monitoring of steganographic frontier model capabilities. We conclude by laying out a comprehensive research program to mitigate future risks of collusion between generative AI models.

---

### Citation for this analysis

Charles Rathkopf, "Philosophical Questions in Secret Collusion among AI Agents: Multi-Agent Deception via Steganography," *AI Deception Papers*, January 2026, https://doi.org/10.48550/arXiv.2402.07510
